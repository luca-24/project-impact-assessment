{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run nlp_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_words(project_doc, goal_docs, use_word_relevance=True, use_goal_similarity=True, \n",
    "                    percentile_threshold=50, n_goals_to_consider=3):\n",
    "    assert use_word_relevance or use_goal_similarity\n",
    "    \n",
    "    goals_to_consider = [g for g,s in project_doc._.predicted_goal_scores][:n_goals_to_consider]\n",
    "    \n",
    "    relevant_words = [w for w,s in project_doc._.word_relevances]\n",
    "    relevance_scores = [s for w,s in project_doc._.word_relevances]\n",
    "    word_scores = []\n",
    "    for token in project_doc:\n",
    "        if token.text.lower() in relevant_words:\n",
    "            if use_word_relevance:\n",
    "                word_relevance = relevance_scores[relevant_words.index(token.text.lower())]\n",
    "            else:\n",
    "                word_relevance = 1\n",
    "                \n",
    "            if use_goal_similarity:\n",
    "                max_similarity = -999\n",
    "                assigned_goal = -1\n",
    "                for gdoc in goal_docs:\n",
    "                    if gdoc._.goal_labels in goals_to_consider:   \n",
    "                        goal_sim = 1 - cosine(token.vector, gdoc._.custom_vector)  \n",
    "                        if goal_sim > max_similarity:\n",
    "                            max_similarity = goal_sim\n",
    "                            assigned_goal = gdoc._.goal_labels\n",
    "            else:\n",
    "                assigned_goal = -1\n",
    "                max_similarity = 1\n",
    "            \n",
    "            score = word_relevance * max_similarity\n",
    "            word_scores.append((token.text, assigned_goal, score))\n",
    "    \n",
    "    score_threshold = np.percentile([s for w,g,s in word_scores], percentile_threshold)\n",
    "    return [(w,g,s) for (w,g,s) in word_scores if s >= score_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Selects a list of sentences from a spacy document, that should represent the summary of the document for the final user. Each sentence is assigned a sdg and a score. The returned list respects the order of the sentences in the original documents.\n",
    "\n",
    "The score assigned to a sentence is given by the product of its relevance score (as computed by \"compute_sentence_relevance\") and the cosine similarity with the closest sdg. The idea is to keep into account both the semantic importance of the sentence for the global meaning of the document and its relevance for the sdg.\n",
    "\n",
    "The parameters \"similarity\", \"perc_relevant_words\" and \"scale_by_tfidf\" are used for the costruction of the sentence vector and for the computation of the similarity with goals.\n",
    "\"\"\"\n",
    "\n",
    "def highlight_sentences(project_doc, goal_docs, use_sentence_relevance=True, use_goal_similarity=True,\n",
    "                        n_sentences=5, n_highlighted_words=5, n_goals_to_consider=3):\n",
    "    assert use_sentence_relevance or use_goal_similarity\n",
    "    \n",
    "    goals_to_consider = [g for g,s in project_doc._.predicted_goal_scores][:n_goals_to_consider]\n",
    "    \n",
    "    sentence_scores = []\n",
    "    for sentence in project_doc.sents:\n",
    "        if use_sentence_relevance:\n",
    "            sentence_relevance = compute_sentence_relevance(sentence, project_doc, perc_relevant_words=1.0)\n",
    "        else:\n",
    "            sentence_relevance = 1\n",
    "        \n",
    "        if use_goal_similarity:\n",
    "            refine_sentence_vector(sentence, project_doc, perc_relevant_words=1.0, scale_by_tfidf=True)\n",
    "            max_similarity = -999\n",
    "            assigned_goal = -1\n",
    "            for gdoc in goal_docs:\n",
    "                if gdoc._.goal_labels in goals_to_consider:   \n",
    "                    goal_sim = sentence._.custom_similarity(gdoc)   \n",
    "                    if goal_sim > max_similarity:\n",
    "                        max_similarity = goal_sim\n",
    "                        assigned_goal = gdoc._.goal_labels\n",
    "        else:\n",
    "            max_similarity = 1\n",
    "        \n",
    "        score = sentence_relevance * max_similarity\n",
    "        sentence_scores.append((sentence.start, sentence.end, assigned_goal, score))\n",
    "    \n",
    "    sorted_scores = sorted([x[-1] for x in sentence_scores], reverse=True)\n",
    "    threshold = sorted_scores[min(n_sentences,len(sorted_scores)-1)]\n",
    "    selected_sentences = [(project_doc[start:end],g,s) for (start,end,g,s) in sentence_scores if s > threshold]\n",
    "    \n",
    "    return selected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(project_docs, goal_docs, n_highlighted_senteces=3, percentile_highlighted_words=50, use_colors=True):\n",
    "    with open('output.html', 'w') as html_writer:\n",
    "        for pdoc in project_docs:\n",
    "            html_writer.write('<h2>'+pdoc._.project_title+'</h2>')\n",
    "            html_writer.write('<h3>True goals:</h3>')\n",
    "            for sdg in pdoc._.goal_labels:\n",
    "                html_writer.write('<p style=\"color:'+goal_color_mapping[sdg]+'\">' + goal_name_mapping[sdg]+'</p>')\n",
    "            html_writer.write('<h3>Predicted Ranking (Top 5):</h3>')\n",
    "            for sdg,score in pdoc._.predicted_goal_scores[:5]:\n",
    "                html_writer.write('<p style=\"color:'+goal_color_mapping[sdg]+'\">' \n",
    "                                  + goal_name_mapping[sdg]+' ('+str(round(score,2))+')</p>')\n",
    "\n",
    "            html_writer.write('<h3>Abstract:</h3>')\n",
    "            highlighted_sentences = highlight_sentences(pdoc, goal_docs, \n",
    "                                                        n_goals_to_consider=3, \n",
    "                                                        use_goal_similarity=True,\n",
    "                                                        use_sentence_relevance=False,\n",
    "                                                        n_sentences=n_highlighted_senteces)\n",
    "\n",
    "            highlighted_words = highlight_words(pdoc, goal_docs,\n",
    "                                                n_goals_to_consider=3,\n",
    "                                                use_goal_similarity=True,\n",
    "                                                use_word_relevance=False,\n",
    "                                                percentile_threshold=percentile_highlighted_words)\n",
    "            \n",
    "            for sent in pdoc.sents:\n",
    "                if sent in [hs[0] for hs in highlighted_sentences]:\n",
    "                    html_writer.write('<b>')\n",
    "                for token in sent:\n",
    "                    if token.text in [hw[0] for hw in highlighted_words]:\n",
    "                        word,assigned_goal,score = highlighted_words.pop(0)\n",
    "                        if use_colors:\n",
    "                            html_writer.write('<span style=\"color:'+goal_color_mapping[assigned_goal]+'\">'+token.text+' </span>')\n",
    "                        else:\n",
    "                            html_writer.write('<mark>'+token.text+'</mark> ')\n",
    "                    else:\n",
    "                        html_writer.write('<span style=\"color:black\">'+token.text+' </span>')\n",
    "                if sent in [hs[0] for hs in highlighted_sentences]:\n",
    "                    html_writer.write('</b>')\n",
    "                html_writer.write('<br><br>')   \n",
    "            html_writer.write('<br><br>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
